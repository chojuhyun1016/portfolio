# ğŸ“¦ order-client.kafka ëª¨ë“ˆ

---

## 1) ëª¨ë“ˆ ê°œìš” (í˜„ì¬ ì½”ë“œ ê¸°ì¤€)

Spring Boot + Spring for Apache Kafka ê¸°ë°˜ì˜ **Producer/Consumer í‘œì¤€ ëª¨ë“ˆ**ì…ë‹ˆë‹¤.  
ìµœì‹  êµ¬ì¡°ëŠ” **ì„¤ì • ê¸°ë°˜(@Bean) + `@Import` ì¡°ë¦½**ê³¼ **ì¡°ê±´ë¶€ ë¹ˆ ë“±ë¡**ìœ¼ë¡œ, í•„ìš”í•  ë•Œë§Œ ì¼œì§€ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.  
ë˜í•œ **MDC(Mapped Diagnostic Context)** ì§€ì›ì„ í†µí•´ **traceId/userId ë“± ì§„ë‹¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ Kafka í—¤ë”ë¡œ ì „íŒŒÂ·ë³µì›**í•˜ì—¬ ë¡œê·¸ ìƒê´€ê´€ê³„ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

| êµ¬ì„±ìš”ì†Œ | ì—­í•  | í•µì‹¬ í¬ì¸íŠ¸(ì½”ë“œ ë°˜ì˜) |
|---|---|---|
| `KafkaModuleConfig` | ëª¨ë“ˆ í†µí•© Import | Producer/Consumer Configë¥¼ **í•œ ë²ˆì— ë¡œë“œ**, ê° ConfigëŠ” `@ConditionalOnProperty`ë¡œ ê°œë³„ ON/OFF |
| `KafkaProducerConfig` | `ProducerFactory` / `KafkaTemplate` | `kafka.producer.enabled=true`ì¼ ë•Œë§Œ í™œì„±, **JsonSerializer(ObjectMapper)**, **LZ4**, `batch.size=65536` |
| `KafkaConsumerConfig` | ë‹¨ê±´/ë°°ì¹˜ `ConcurrentKafkaListenerContainerFactory` | `kafka.consumer.enabled=true`ì¼ ë•Œë§Œ í™œì„±, **`MANUAL_IMMEDIATE` ack**, ê¸°ë³¸ **ì¬ì‹œë„ ì—†ìŒ** |
| `KafkaProducerCluster` | ì „ì†¡ ì„œë¹„ìŠ¤ | `@ConditionalOnBean(KafkaTemplate)` â†’ Producer ì¼œì¡Œì„ ë•Œë§Œ ë“±ë¡, **SmartLifecycle**(ìš°ì„  ì‹œì‘/ìµœí›„ ì¢…ë£Œ), `sendMessage(data, topic)` |
| `KafkaProducerProperties` | í”„ë¡œë“€ì„œ ì„¤ì • | `kafka.producer.enabled`, `bootstrap-servers`(í•„ìˆ˜, ê²€ì¦) |
| `KafkaConsumerProperties` | ì»¨ìŠˆë¨¸ ì„¤ì • | `kafka.consumer.enabled`, `bootstrap-servers`(í•„ìˆ˜, ê²€ì¦), `option.*`(poll/í˜ì¹˜/ì»¤ë°‹) |
| `KafkaSSLProperties` | SSL/SASL ê³µí†µ | `kafka.ssl.enabled=true`ì¼ ë•Œë§Œ ë³´ì•ˆ ì„¤ì • ì£¼ì… |
| `KafkaTopicProperties` + `KafkaTopicEntry` | í† í”½ ë§¤í•‘ | `kafka.topic` ë¦¬ìŠ¤íŠ¸ ë°”ì¸ë”©, `getName(category[, region])` ì œê³µ(ë¯¸ë§¤í•‘ ì‹œ Fail-fast) |
| **MDC ì§€ì›** | ì§„ë‹¨ ì»¨í…ìŠ¤íŠ¸ ì „íŒŒ | **ì˜µì…˜**: `kafka.mdc.enabled=true`ì¼ ë•Œ, ProducerëŠ” MDCë¥¼ í—¤ë”ì— **ì£¼ì…**, ConsumerëŠ” ìˆ˜ì‹  ì‹œ **ë³µì› í›„ ì²˜ë¦¬/ì •ë¦¬** |
| **í…ŒìŠ¤íŠ¸** | IT/ë‹¨ìœ„ ê²€ì¦ | `EmbeddedKafka` í†µí•© ê²€ì¦(`KafkaTemplate`â†’Raw `KafkaConsumer` ìˆ˜ì‹ ), enabled/disabled ì¡°ê±´ë¶€ ë¹ˆ ìƒì„± í…ŒìŠ¤íŠ¸ |

> íŒ¨í‚¤ì§€ ì˜ˆì‹œ:  
> `org.example.order.client.kafka.config.*` / `.config.producer` / `.config.consumer` / `.config.properties` / `.service`

---

## 2) ì„¤ì • (application.yml / profile)

### 2.1 ìµœì†Œ/ê³µí†µ (ì½”ë“œ ë°˜ì˜)

ë³´ì•ˆ(ì˜µì…˜) â€” MSK IAM/SASL ë“±

    kafka:
      ssl:
        enabled: false                 # ê¸°ë³¸ false, í•„ìš” ì‹œ true
        security-protocol: SASL_SSL
        sasl-mechanism: AWS_MSK_IAM
        sasl-jaas-config: software.amazon.msk.auth.iam.IAMLoginModule required;
        sasl-client-callback-handler-class: software.amazon.msk.auth.iam.IAMClientCallbackHandler

í”„ë¡œë“€ì„œ

    kafka:
      producer:
        enabled: true                  # âœ… ì¼œë©´ ProducerFactory/KafkaTemplate ìƒì„±
        bootstrap-servers: localhost:9092

ì»¨ìŠˆë¨¸

    kafka:
      consumer:
        enabled: true                  # âœ… ì¼œë©´ ListenerContainerFactory ìƒì„±(@EnableKafka)
        bootstrap-servers: localhost:9092
        option:
          max-fail-count: 1
          max-poll-records: 1000
          fetch-max-wait-ms: 500
          fetch-max-bytes: 52428800        # 50MiB
          max-poll-interval-ms: 300000     # 5ë¶„
          idle-between-polls: 0
          auto-offset-reset: earliest
          enable-auto-commit: false        # MANUAL_IMMEDIATE ì •ì±…ê³¼ ì¼ì¹˜

ì„œë¹„ìŠ¤ë³„ í† í”½ ë§¤í•‘(ì„ íƒ)

    kafka:
      topic:
        - category: order-local
          name: "beta-order-local"
        - category: order-api
          name: "beta-order-api"

MDC ì „íŒŒ ì˜µì…˜(ì„ íƒ)

    kafka:
      mdc:
        enabled: true                  # âœ… MDC í—¤ë” ì „íŒŒ/ë³µì› On/Off
        keys:                          # ì „íŒŒí•  MDC í‚¤ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸(ë¯¸ì„¤ì • ì‹œ ì „ì²´ ì „íŒŒ)
          - traceId
          - userId
          - sessionId

> **ë³´ì•ˆ ì„¤ì • ì£¼ì… ì¡°ê±´**: `kafka.ssl.enabled=true`ì¼ ë•Œì—ë§Œ Producer/Consumer ê³µí†µ í´ë¼ì´ì–¸íŠ¸ ì„¤ì •ì— SECURITY_PROTOCOL / SASL ê°’ë“¤ì´ ì ìš©ë©ë‹ˆë‹¤.  
> **í”„ë¡œë“€ì„œ ì§ë ¬í™”**: ì½”ë“œ ìƒ **JsonSerializer ê³ ì •** + **ê³µí†µ ObjectMapper** ì£¼ì…(ë„ë©”ì¸ ê°ì²´ ì „ì†¡ í‘œì¤€í™”).  
> **ì••ì¶•/ë°°ì¹˜**: `LZ4` + `batch.size=65536`(64KiB) ê¸°ë³¸ ì ìš©.  
> **MDC ì „íŒŒ**: `kafka.mdc.enabled=true` ì‹œ, **Producerâ†’í—¤ë” ì£¼ì… / Consumerâ†’MDC ë³µì›**ì´ ìë™ ì ìš©ë©ë‹ˆë‹¤.

---

## 3) ë¹ ë¥¸ ì‹œì‘ (ê°€ì¥ ì¤‘ìš”í•œ ì‚¬ìš©ë²•)

### 3.1 Producer â€” ë©”ì‹œì§€ ì „ì†¡ (ì„œë¹„ìŠ¤ì—ì„œ ê°„ë‹¨ ì‚¬ìš©, MDC ìë™ ì£¼ì…)

    @Service
    @RequiredArgsConstructor
    public class OrderEventPublisher {
      private final KafkaProducerCluster producer; // SmartLifecycle, KafkaTemplate ë˜í•‘

      public void publishOrderCreated(OrderCreatedEvent evt, String topic) {
        // topic: KafkaTopicProperties.getName(MessageCategory.ORDER_LOCAL) ë“±ìœ¼ë¡œ ì£¼ì… ê¶Œì¥
        // MDC(enabled)ì¼ ê²½ìš° traceId/userId ë“±ì´ í—¤ë”ì— ìë™ í¬í•¨ë¨
        producer.sendMessage(evt, topic);
      }
    }

- `KafkaProducerCluster#sendMessage(Object data, String topic)`:
    - `MessageBuilder`ë¡œ payload + `KafkaHeaders.TOPIC` ì„¤ì • í›„ `KafkaTemplate.send()` í˜¸ì¶œ
    - **MDC í™œì„± ì‹œ** í˜„ì¬ Thread MDCë¥¼ í—¤ë”ë¡œ ë³µì‚¬(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš© ê°€ëŠ¥)
    - ë°˜í™˜ëœ `CompletableFuture`ì— **ì„±ê³µ/ì‹¤íŒ¨ ì½œë°±**(ì˜¤í”„ì…‹/ì—ëŸ¬ ë¡œê·¸)
- **Lifecycle**: ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ **ê°€ì¥ ë¨¼ì € ì‹œì‘**, ì¢…ë£Œ ì‹œ **flush í›„ ì•ˆì „ ì¢…ë£Œ**

### 3.2 Consumer â€” ë¦¬ìŠ¤ë„ˆ ì‘ì„± (MANUAL_IMMEDIATE ack, MDC ìë™ ë³µì›)

    @Component
    public class OrderEventListener {

      @KafkaListener(
          topics = "#{@kafkaTopicProperties.getName(T(org.example.order.core.messaging.order.code.MessageCategory).ORDER_LOCAL)}",
          groupId = "order-service",
          containerFactory = "kafkaListenerContainerFactory"  // ë‹¨ê±´ ë¦¬ìŠ¤ë„ˆ
      )
      public void onMessage(org.apache.kafka.clients.consumer.ConsumerRecord<String, String> rec,
                            org.springframework.kafka.support.Acknowledgment ack) {
        try {
          // JSON â†’ DTO ë§¤í•‘ í•„ìš” ì‹œ ObjectMapper ì‚¬ìš© (í˜„ì¬ ConsumerFactoryëŠ” StringDeserializer)
          // MDC(enabled)ì¼ ê²½ìš° ì¸í„°ì…‰í„°ê°€ í—¤ë”â†’MDC ë³µì› (traceId/userId ë“±)
          process(rec.value());
          ack.acknowledge(); // âœ… MANUAL_IMMEDIATE : í˜¸ì¶œ ì‹œ ì¦‰ì‹œ ì»¤ë°‹
        } catch (Exception e) {
          // ê¸°ë³¸ ì—ëŸ¬í•¸ë“¤ëŸ¬ëŠ” "ì¬ì‹œë„ ì—†ìŒ" â€” ì •ì±… í•„ìš” ì‹œ êµì²´ ê°€ëŠ¥
          throw e;
        } finally {
          // ì¸í„°ì…‰í„°ê°€ ì •ë¦¬í•˜ì§€ë§Œ, Listener ë ˆë²¨ì—ì„œë„ ëˆ„ìˆ˜ ë°©ì§€ ì°¨ì›ì—ì„œ clear ê°€ëŠ¥
          // MDC.clear();
        }
      }
    }

- ì»¨í…Œì´ë„ˆ íŒ©í† ë¦¬:
    - `kafkaListenerContainerFactory()` : **ë‹¨ê±´** ë¦¬ìŠ¤ë„ˆ, `MANUAL_IMMEDIATE`
    - `kafkaBatchListenerContainerFactory()` : **ë°°ì¹˜** ë¦¬ìŠ¤ë„ˆ, `MAX_POLL_RECORDS` ë“± ì˜µì…˜ ë°˜ì˜ + `MANUAL_IMMEDIATE`
- ì£¼ì˜: `enable-auto-commit=false`ì¼ ë•Œ **ë°˜ë“œì‹œ `ack.acknowledge()` í˜¸ì¶œ**ë¡œ ì»¤ë°‹ ì œì–´

---

## 4) ë™ì‘ íë¦„

    kafka.producer.enabled=true
      â””â”€ KafkaProducerConfig
           â”œâ”€ ProducerFactory<String,Object>  (JsonSerializer + LZ4 + batch.size)
           â”œâ”€ KafkaTemplate<String,Object>
           â””â”€ (ì˜µì…˜) MDCProducerInterceptor / ë©”ì‹œì§€ ë¹Œë” í›… â†’ MDC í—¤ë” ì£¼ì…

    kafka.consumer.enabled=true
      â””â”€ KafkaConsumerConfig (@EnableKafka)
           â”œâ”€ ConcurrentKafkaListenerContainerFactory (ë‹¨ê±´)  [Ack=MANUAL_IMMEDIATE]
           â”œâ”€ ConcurrentKafkaListenerContainerFactory (ë°°ì¹˜)  [Ack=MANUAL_IMMEDIATE, Batch ì˜µì…˜]
           â”œâ”€ DefaultErrorHandler(FixedBackOff 0,0)  // ê¸°ë³¸ ì¬ì‹œë„ ì—†ìŒ
           â””â”€ (ì˜µì…˜) MDCConsumerInterceptor â†’ í—¤ë”â†’MDC ë³µì› â†’ ì²˜ë¦¬ í›„ MDC ì •ë¦¬

- **SSL/SASL**: `kafka.ssl.enabled=true` â†’ `security.protocol`, `sasl.*` ì†ì„±ë“¤ì„ Producer/Consumer ê³µí†µ ì„¤ì •ì— ì£¼ì…
- **Topic ë§¤í•‘**: `KafkaTopicProperties`ì—ì„œ `MessageCategory`(+ì„ íƒ `RegionCode`) â†’ í† í”½ëª… ì¡°íšŒ(Fail-fast)

---

## 5) í”„ë¡œí¼í‹° ìƒì„¸

### 5.1 Producer
- `kafka.producer.enabled` (boolean) : **ON/OFF ìŠ¤ìœ„ì¹˜**
- `kafka.producer.bootstrap-servers` (string) : **í•„ìˆ˜** (ê²€ì¦ ì• ë…¸í…Œì´ì…˜ ì ìš©)

### 5.2 Consumer
- `kafka.consumer.enabled` (boolean) : **ON/OFF ìŠ¤ìœ„ì¹˜**
- `kafka.consumer.bootstrap-servers` (string) : **í•„ìˆ˜** (ê²€ì¦ ì• ë…¸í…Œì´ì…˜ ì ìš©)
- `kafka.consumer.option.*` : poll/í˜ì¹˜/ì˜¤í”„ì…‹/ìœ íœ´ì‹œê°„ ë“± ì„¸ë¶€ íŠœë‹ íŒŒë¼ë¯¸í„°

### 5.3 SSL/SASL
- `kafka.ssl.enabled` (boolean) : ë³´ì•ˆ ì„¤ì • ì‚¬ìš© ì—¬ë¶€
- `kafka.ssl.security-protocol` / `kafka.ssl.sasl-mechanism` / `kafka.ssl.sasl-jaas-config` / `kafka.ssl.sasl-client-callback-handler-class`

### 5.4 Topic
- `kafka.topic` (list of `KafkaTopicEntry`) : `category`, `regionCode(ì˜µì…˜)`, `name`
- ì¡°íšŒ:
    - `getName(MessageCategory category)`
    - `getName(MessageCategory category, RegionCode regionCode)`

### 5.5 MDC (ì˜µì…˜)
- `kafka.mdc.enabled` (boolean) : **MDC ì „íŒŒ/ë³µì› ìŠ¤ìœ„ì¹˜**
- `kafka.mdc.keys` (list) : **ì „íŒŒí•  MDC í‚¤ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸**(ë¯¸ì„¤ì • ì‹œ ì „ì²´ ì „íŒŒ)

---

## 6) í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ (ì½”ë“œ ë°˜ì˜ í•´ì„¤)

### 6.1 EmbeddedKafka í†µí•© í…ŒìŠ¤íŠ¸ â€” `KafkaProducerIT`

- `@EmbeddedKafka`ë¡œ **ë¸Œë¡œì»¤ ê¸°ë™**(í…ŒìŠ¤íŠ¸ í† í”½ 1ê°œ)
- `KafkaTemplate`ìœ¼ë¡œ **ë©”ì‹œì§€ ì „ì†¡** â†’ **Raw `KafkaConsumer`**ë¡œ í´ë§ ìˆ˜ì‹  ê²€ì¦
- JsonSerializer íŠ¹ì„±: ë¬¸ìì—´ payloadê°€ **JSON ë¬¸ìì—´(ë”°ì˜´í‘œ í¬í•¨)**ë¡œ ì „ì†¡ë  ìˆ˜ ìˆì–´, ìˆ˜ì‹ ê°’ ë¹„êµ ì‹œ `"value"` ë„ í—ˆìš©

í•µì‹¬ í¬ì¸íŠ¸:

    String value = "hello-kafka-" + UUID.randomUUID();
    String jsonEncodedValue = "\"" + value + "\""; // JsonSerializerì¼ ê²½ìš° ìˆ˜ì‹  ê°’

    // ë§¤ì¹­ ì¡°ê±´: value ë˜ëŠ” jsonEncodedValue
    if (key.equals(recKey) && (value.equals(recVal) || jsonEncodedValue.equals(recVal))) {
        matched = true;
    }

### 6.2 ì¡°ê±´ë¶€ ë¹ˆ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸ â€” `KafkaProducerConfigDisabledTest`
- `kafka.producer.enabled=false` â‡’ **KafkaTemplate ë¹ˆ ë¯¸ìƒì„±** (`NoSuchBeanDefinitionException` ê²€ì¦)

### 6.3 ì¡°ê±´ë¶€ ë¹ˆ í™œì„±í™” í…ŒìŠ¤íŠ¸ â€” `KafkaProducerConfigEnabledTest`
- `kafka.producer.enabled=true` + ë”ë¯¸ `bootstrap-servers` â‡’ **KafkaTemplate ë¹ˆ ìƒì„±** (ì‹¤ ë¸Œë¡œì»¤ ì—°ê²° ì—†ì´)

### 6.4 MDC ì „íŒŒ/ë³µì› í…ŒìŠ¤íŠ¸ (ì„ íƒ)
- Producer ì „ì†¡ ì „ `MDC.put("traceId", "...")` ì„¤ì • â†’ Consumer ìˆ˜ì‹  ì‹œ í—¤ë”ì— ë™ì¼ ê°’ ì¡´ì¬ ë° ë¡œê·¸ ìƒ í¬í•¨ í™•ì¸
- Listener ì²˜ë¦¬ ì¢…ë£Œ í›„ **MDC ì •ë¦¬**(ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€) ê²€ì¦

---

## 7) ìš´ì˜ íŒ & ê¶Œì¥ ì„¤ì •

- **Idempotent/acks/retries**: í•„ìš” ì‹œ Producerì— `enable.idempotence=true`, `acks=all`, `retries` ë“± ì¶”ê°€(í˜„ì¬ ê¸°ë³¸ì€ LZ4+batch).
- **Key ì„¤ê³„**: ìˆœì„œ/íŒŒí‹°ì…˜ ì§€ì—­ì„±ì´ í•„ìš”í•œ ì´ë²¤íŠ¸ëŠ” **ë¹„ì¦ˆë‹ˆìŠ¤ í‚¤**(ì˜ˆ: `orderId`) ì‚¬ìš©.
- **DLT/ì¬ì‹œë„ ì •ì±…**: ê¸°ë³¸ ì—ëŸ¬í•¸ë“¤ëŸ¬ëŠ” **ì¬ì‹œë„ ì—†ìŒ**. í•„ìš” ì‹œ `DefaultErrorHandler` + DLT ë¦¬ì»¤ë²„ëŸ¬ë¡œ êµì²´.
- **ë³´ì•ˆ(MSK/IAM)**: ìš´ì˜ì€ `kafka.ssl.enabled=true` í”„ë¡œíŒŒì¼, ë¡œì»¬/í…ŒìŠ¤íŠ¸ëŠ” `false`ë¡œ ê°„ë‹¨ ìœ ì§€.
- **ê´€ì¸¡ì„±**: `KafkaProducerCluster` ì „ì†¡ ë¡œê·¸(í† í”½/ì˜¤í”„ì…‹/ì‹¤íŒ¨), ì»¨ìŠˆë¨¸ Lag/ì˜¤í”„ì…‹ ì»¤ë°‹ ì§€í‘œ ëª¨ë‹ˆí„°ë§.
- **MDC ì„±ëŠ¥/ì•ˆì „**: í‚¤ ìˆ˜ ìµœì†Œí™”(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©), ë°”ì´ë„ˆë¦¬/ëŒ€í˜• ê°’ ê¸ˆì§€, ì²˜ë¦¬ í›„ **MDC.clear()** ìŠµê´€í™”.

---

## 8) í™•ì¥/ê°œì„  ì œì•ˆ (ì„ íƒ)

- **Producer ì˜µì…˜ ë³´ê°•**: `linger.ms`, `buffer.memory`, `delivery.timeout.ms`, `request.timeout.ms`, `retries`, `max.in.flight.requests.per.connection` ë“± yml ë…¸ì¶œ.
- **Consumer ì¬ì‹œë„/ë³µêµ¬**: `DefaultErrorHandler` + DeadLetterPublishingRecoverer, ì¬ì‹œë„/ìŠ¤í‚µ ë¶„ë¦¬ ì •ì±…í™”.
- **Value SerDe ë‹¤ì–‘í™”**: Consumerì— `JsonDeserializer`(íƒ€ì… ë°”ì¸ë”©), Producerì— `Headers` ê¸°ë°˜ íƒ€ì… íŒíŠ¸.
- **í† í”½ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í‘œì¤€**: `<bounded-context>.<event-name>` (`order.local`, `order.api` ë“±) + ì§€ì—­ì½”ë“œ íŒŒí‹°ì…”ë‹.
- **í…ŒìŠ¤íŠ¸ ìœ í‹¸**: ì„ì‹œ í† í”½/ê·¸ë£¹ ID í—¬í¼, Awaitility ê¸°ë°˜ ëŒ€ê¸° í—¬í¼.
- **MDC ì „íŒŒ í‘œì¤€í™”**: í‚¤ ë„¤ì´ë° ì»¨ë²¤ì…˜(`traceId`, `spanId`, `userId`) ë° ë³´ì•ˆ ë¯¼ê°ì •ë³´ í•„í„°ë§ ì •ì±….

---

## 9) í•µì‹¬ ì½”ë“œ ìŠ¤ë‹ˆí«(ë°˜ì˜ í™•ì¸)

### 9.1 Producer ì„¤ì • ìš”ì§€ (`KafkaProducerConfig`)

    configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
    configProps.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, CompressionType.LZ4.name);
    configProps.put(ProducerConfig.BATCH_SIZE_CONFIG, 65_536);
    if (sslProperties.isEnabled()) {
        // SECURITY_PROTOCOL / SASL_* ì£¼ì…
    }
    // (ì˜µì…˜) MDCProducerInterceptor ë“±ë¡ ë˜ëŠ” KafkaProducerCluster ë‚´ë¶€ì—ì„œ í—¤ë” ì£¼ì… ë¡œì§ ì‚¬ìš©
    DefaultKafkaProducerFactory<String, Object> factory =
        new DefaultKafkaProducerFactory<>(configProps);
    factory.setValueSerializer(new JsonSerializer<>(ObjectMapperFactory.defaultObjectMapper()));
    return new KafkaTemplate<>(factory);

### 9.2 Consumer ì„¤ì • ìš”ì§€ (`KafkaConsumerConfig`)

    factory.setCommonErrorHandler(new DefaultErrorHandler(new FixedBackOff(0L, 0L))); // ì¬ì‹œë„ ì—†ìŒ
    ContainerProperties cp = factory.getContainerProperties();
    cp.setAckMode(ContainerProperties.AckMode.MANUAL_IMMEDIATE); // ìˆ˜ë™ ì»¤ë°‹
    // ë°°ì¹˜ íŒ©í† ë¦¬ì—ì„œëŠ” MAX_POLL_RECORDS/FETCH_* ë“± option ë°˜ì˜ + setBatchListener(true)
    // (ì˜µì…˜) MDCConsumerInterceptorë¥¼ ì»¨í…Œì´ë„ˆ íŒ©í† ë¦¬ì— ë“±ë¡í•˜ì—¬ í—¤ë”â†’MDC ë³µì›

### 9.3 ì „ì†¡ ì„œë¹„ìŠ¤ ìš”ì§€ (`KafkaProducerCluster`) â€” MDC í—¤ë” ì£¼ì… ì˜ˆì‹œ

    Message<Object> message = MessageBuilder.withPayload(data)
            .setHeader(KafkaHeaders.TOPIC, topic)
            .build();

    // (ì˜µì…˜) MDC enabled & keys í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì ìš© ì‹œ
    Map<String, String> ctx = MDC.getCopyOfContextMap();
    if (ctx != null) {
        Set<String> allow = mdcProps.getKeysOrNull(); // nullì´ë©´ ì „ì²´
        ctx.forEach((k, v) -> {
            if (allow == null || allow.contains(k)) {
                message.getHeaders().add(k, v == null ? new byte[0] : v.getBytes(StandardCharsets.UTF_8));
            }
        });
    }

    kafkaTemplate.send(message).whenComplete((result, ex) -> {
        if (ex == null) {
            log.info("Sending kafka message - topic: {}, offset: {}, traceId: {}",
                     topic,
                     result.getRecordMetadata().offset(),
                     MDC.get("traceId"));
        } else {
            log.error("error : Sending kafka message failed - topic: {}, message: {}",
                      topic, ex.getMessage(), ex);
        }
    });

### 9.4 Consumer ìˆ˜ì‹  ì‹œ MDC ë³µì› ì˜ˆì‹œ (`MDCConsumerInterceptor` í˜¹ì€ Listener ì‹œì‘ë¶€)

    // í—¤ë” â†’ MDC ë³µì›
    for (Header h : record.headers()) {
        MDC.put(h.key(), h.value() == null ? null : new String(h.value(), StandardCharsets.UTF_8));
    }
    try {
        // ì‹¤ì œ ì²˜ë¦¬
        process(record.value());
        ack.acknowledge();
    } finally {
        MDC.clear(); // ëˆ„ìˆ˜ ë°©ì§€
    }

### 9.5 EmbeddedKafka IT ìš”ì§€ (`KafkaProducerIT`)

    kafkaTemplate.send(TOPIC, key, value).join();
    try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {
        consumer.subscribe(Collections.singletonList(TOPIC));
        // í´ë§í•˜ë©° value ë˜ëŠ” "value"(Json ë¬¸ìì—´) ë§¤ì¹­ í™•ì¸
    }

---

## 10) ë§ˆì§€ë§‰ í•œ ì¤„ ìš”ì•½
**â€œyml ìŠ¤ìœ„ì¹˜ë¡œ Producer/Consumerë¥¼ ëª…í™•íˆ ì œì–´í•˜ê³ , ProducerëŠ” `KafkaProducerCluster.sendMessage()`â€”ConsumerëŠ” `MANUAL_IMMEDIATE ack`â€”ë¡œ ì¼ê´€ ì‚¬ìš©.â€**  
JsonSerializer + LZ4 + ë³´ì•ˆ ì˜µì…˜ + **MDC ì „íŒŒ/ë³µì›**ê¹Œì§€ **í‘œì¤€í™”ëœ ì„¤ì •/ì½”ë“œ ê²½ë¡œ**ë¡œ ì•ˆì •Â·ê°€ì‹œì„± ìˆê²Œ ìš´ì˜í•©ë‹ˆë‹¤.
