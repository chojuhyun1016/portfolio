# ğŸ§° order-batch ì„œë¹„ìŠ¤ README (Spring Batch Â· DLQ ì¬ì²˜ë¦¬ Â· S3 ì—…ë¡œë“œ Â· Secrets/Crypto í‚¤ ì‹œë”© Â· ìš´ì˜ ê°€ì´ë“œ)

Spring Boot ê¸°ë°˜ ë°°ì¹˜ ëª¨ë“ˆì…ë‹ˆë‹¤.  
Kafka DLQ(Dead Letter) ì¬ì²˜ë¦¬, S3 ë¡œê·¸ ë™ê¸°í™”(ì‹œì‘/ì¢…ë£Œ í›…), Secrets/Crypto í‚¤ ì‹œë”©(AES128/AES256/AESGCM/HMAC_SHA256)ê¹Œì§€ ìš´ì˜ì— í•„ìš”í•œ ê²½ë¡œë¥¼
í¬í•¨í•©ë‹ˆë‹¤.  
ì‹¤í–‰ í›„ ì¢…ë£Œë˜ëŠ” ë‹¨ë°œì„± ë°°ì¹˜ì´ë©°, **ì¡ ìƒíƒœ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œì½”ë“œ ë§¤í•‘(ì„±ê³µ=0, ê·¸ ì™¸=1)** ì„ ì§€ì›í•©ë‹ˆë‹¤.

---

## 1) ëª¨ë“ˆ ì¡°ë¦½/ì˜¤í† êµ¬ì„±

- **í•µì‹¬ ì˜¤í† êµ¬ì„±:** `OrderBatchConfig` (í˜„ì¬ ì½”ë“œ ë°˜ì˜)
    - Import: `OrderCoreConfig`, `WebAutoConfiguration`, `TsidInfraConfig`
    - ImportAutoConfiguration: `S3AutoConfiguration`, `KafkaAutoConfiguration`, `CacheAutoConfiguration`,
      `ApplicationAutoConfiguration`
    - ComponentScan: `config/crypto/facade/job/lifecycle/service`
    - Properties: `BatchProperties`, `AppCryptoKeyProperties`
    - ObjectMapper ê¸°ë³¸ ë¹ˆ ì œê³µ(`ObjectMapperFactory`) â€” `@ConditionalOnMissingBean`

```java

@Configuration
@Import({
        OrderCoreConfig.class,
        WebAutoConfiguration.class,
        TsidInfraConfig.class
})
@ImportAutoConfiguration({
        S3AutoConfiguration.class,
        KafkaAutoConfiguration.class,
        CacheAutoConfiguration.class,
        ApplicationAutoConfiguration.class
})
@ComponentScan(basePackages = {
        "org.example.order.batch.config",
        "org.example.order.batch.crypto",
        "org.example.order.batch.facade",
        "org.example.order.batch.job",
        "org.example.order.batch.lifecycle",
        "org.example.order.batch.service"
})
@EnableConfigurationProperties({
        BatchProperties.class,
        AppCryptoKeyProperties.class
})
@RequiredArgsConstructor
public class OrderBatchConfig {

    @Bean
    @ConditionalOnMissingBean(ObjectMapper.class)
    ObjectMapper objectMapper() {
        return ObjectMapperFactory.defaultObjectMapper();
    }
}
```

- **ë°°ì¹˜ ì•± ì—”íŠ¸ë¦¬:** `OrderBatchApplication`
    - `WebApplicationType.NONE`, ì‹¤í–‰ í›„ `SpringApplication.exit(ctx)` â†’ `System.exit(exitCode)`
    - JVM ê¸°ë³¸ íƒ€ì„ì¡´: `UTC`

```java

@SpringBootApplication
@Import({
        OrderBatchConfig.class,
        FlywayDevLocalStrategy.class,
        OrderCoreConfig.class
})
public class OrderBatchApplication {

    public static void main(String[] args) {
        SpringApplication app = new SpringApplication(OrderBatchApplication.class);
        app.setWebApplicationType(WebApplicationType.NONE);

        ConfigurableApplicationContext ctx = app.run(args);
        int exitCode = SpringApplication.exit(ctx);
        System.exit(exitCode);
    }

    @PostConstruct
    void setTimeZone() {
        TimeZone.setDefault(TimeZone.getTimeZone("UTC"));
    }
}
```

---

## 2) ì¡ êµ¬ì„± (DLQ ì¬ì²˜ë¦¬)

- êµ¬ì„± í´ë˜ìŠ¤: `job.deadletter.OrderDeadLetterJobConfig`
    - Job ì´ë¦„: `ORDER_DEAD_LETTER_JOB`
    - `RunIdIncrementer` ì ìš©(ì¬ì‹¤í–‰ ì¶©ëŒ ë°©ì§€), `preventRestart()`
    - Step: `ORDER_DEAD_LETTER_JOB.retry`
    - Tasklet: `facade.retry()` ìˆ˜í–‰(ì˜ˆì™¸ ë¡œê¹… í›„ ì „íŒŒ)

```java

@Configuration
@RequiredArgsConstructor
@Slf4j
public class OrderDeadLetterJobConfig {

    private final OrderDeadLetterFacade facade;

    public static final String JOB_NAME = "ORDER_DEAD_LETTER_JOB";

    @Bean(name = JOB_NAME)
    public Job job(JobRepository jobRepository, Step orderDeadLetterStep) {
        return new JobBuilder(JOB_NAME, jobRepository)
                .incrementer(new RunIdIncrementer())
                .start(orderDeadLetterStep)
                .preventRestart()
                .build();
    }

    @Bean
    @JobScope
    public Step orderDeadLetterStep(JobRepository jobRepository,
                                    Tasklet orderDeadLetterTasklet,
                                    PlatformTransactionManager tx) {
        return new StepBuilder(JOB_NAME + ".retry", jobRepository)
                .tasklet(orderDeadLetterTasklet, tx)
                .build();
    }

    @Bean
    public Tasklet orderDeadLetterTasklet() {
        return (contribution, chunkContext) -> {
            log.info("OrderDeadLetterJob start");
            facade.retry();
            return RepeatStatus.FINISHED;
        };
    }
}
```

- **ëŒ€ì•ˆ Tasklet(íŒŒë¼ë¯¸í„° í•„ìš” ì‹œ):** `job.tasklet.OrderDeadLetterRetryTasklet` (`@StepScope`)

```java

@Slf4j
@StepScope
@Component
@RequiredArgsConstructor
public class OrderDeadLetterRetryTasklet implements Tasklet {

    private final OrderDeadLetterFacade facade;

    @Override
    public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) {
        log.info("OrderDeadLetterJob start");
        facade.retry();
        return RepeatStatus.FINISHED;
    }
}
```

---

## 3) Kafka í† í”½/ì»¨ìŠˆë¨¸/í”„ë¡œë“€ì„œ

### 3.1 í† í”½ ì´ë¦„ ë¹ˆ (ìš´ì˜ìš© ì´ë¦„ ë§¤í•‘)

- `KafkaListenerTopicConfig` â€” `MessageOrderType` ê¸°ë°˜ ì´ë¦„ ì£¼ì…

```java

@Configuration
@RequiredArgsConstructor
@EnableConfigurationProperties(KafkaTopicProperties.class)
public class KafkaListenerTopicConfig {

    @Bean
    public String orderLocalTopic(KafkaTopicProperties p) {
        return p.getName(MessageOrderType.ORDER_LOCAL);
    }

    @Bean
    public String orderApiTopic(KafkaTopicProperties p) {
        return p.getName(MessageOrderType.ORDER_API);
    }

    @Bean
    public String orderCrudTopic(KafkaTopicProperties p) {
        return p.getName(MessageOrderType.ORDER_CRUD);
    }

    @Bean
    public String orderRemoteTopic(KafkaTopicProperties p) {
        return p.getName(MessageOrderType.ORDER_REMOTE);
    }

    @Bean
    public String orderDlqTopic(KafkaTopicProperties p) {
        return p.getName(MessageOrderType.ORDER_DLQ);
    }

    @Bean
    public String orderAlarmTopic(KafkaTopicProperties p) {
        return p.getName(MessageOrderType.ORDER_ALARM);
    }
}
```

### 3.2 ë¡œì»¬ í”„ë¡œí•„ í† í”½ ìë™ ìƒì„±/ë³´ì¥

- `KafkaTopicsConfig` (`@Profile("local")`)
    - `KafkaAdmin` ê²½ë¡œ + `ApplicationReadyEvent` ì´í›„ `AdminClient`ë¡œ ìµœì¢… ë³´ì¥(`ensure-at-startup=true`)
    - ë¸Œë¡œì»¤ ì¤€ë¹„ ëŒ€ê¸°/ì¬ì‹œë„ í¬í•¨
    - ê¸°ë³¸ ë¡œì»¬ í† í”½: `local-order-*`

```java

@Configuration
@Profile("local")
@ConditionalOnProperty(prefix = "app.kafka", name = "auto-create-topics", havingValue = "true", matchIfMissing = true)
public class KafkaTopicsConfig {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)
}
```

### 3.3 DLQ ì „ìš© ConsumerFactory (DeadLetter<?> ì—­ì§ë ¬í™”)

- `KafkaDeadLetterConsumerConfig`
    - value: `DeadLetter<?>`, `JsonDeserializer`(ignoreTypeHeaders, trustedPackages ë™ì )
    - í™œì„± í”„ë¡œí•„ `local/test` â†’ `addTrustedPackages("*")`, ê·¸ ì™¸ ìš´ì˜ íŒ¨í‚¤ì§€ í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©

```java

@Configuration
public class KafkaDeadLetterConsumerConfig {

    private static final String CONTRACT_PACKAGE_PREFIX = "org.example.order.contract.*";

    @Bean
    @Qualifier("deadLetterConsumerFactory")
    public ConsumerFactory<String, DeadLetter<?>> deadLetterConsumerFactory() {
        Map<String, Object> props = new HashMap<>(kafkaProperties.buildConsumerProperties(null));
        StringDeserializer key = new StringDeserializer();
        JsonDeserializer<DeadLetter<?>> val = new JsonDeserializer<>(DeadLetter.class, objectMapper);

        val.ignoreTypeHeaders();
        val.setUseTypeMapperForKey(false);

        String prof = System.getProperty("spring.profiles.active", "local");
        if ("local".equals(prof) || "test".equals(prof)) {
            val.addTrustedPackages("*");
        } else {
            val.addTrustedPackages(CONTRACT_PACKAGE_PREFIX);
        }
        return new DefaultKafkaConsumerFactory<>(props, key, val);
    }
}
```

### 3.4 DLQ íŒŒì‚¬ë“œ â€” ë©€í‹° íŒŒí‹°ì…˜ ì•ˆì „ ì»¤ë°‹

- `facade.retry.impl.OrderDeadLetterFacadeImpl`
    - `@Qualifier("deadLetterConsumerFactory")` ì‚¬ìš©
    - ëª¨ë“  íŒŒí‹°ì…˜ assign â†’ ì»¤ë°‹ ì˜¤í”„ì…‹ ìˆìœ¼ë©´ seek, ì—†ìœ¼ë©´ beginning
    - í•œ ë²ˆ `poll(Duration.ofSeconds(2))`ë¡œ ë“¤ì–´ì˜¨ ë ˆì½”ë“œë§Œ ì²˜ë¦¬
    - íŒŒí‹°ì…˜ë³„ ì²˜ë¦¬ í›„ **(ë§ˆì§€ë§‰ offset + 1) ì»¤ë°‹**
    - í—¤ë” ì •ê·œí™”(`RETRY_COUNT_HEADER = x-retry-count`), íƒ€ì… ì•ˆì „ íŒŒì‹±(`MessageOrderType`)

```java

@Slf4j
@Component
@RequiredArgsConstructor
public class OrderDeadLetterFacadeImpl implements OrderDeadLetterFacade {

    private final OrderDeadLetterService orderDeadLetterService;
    @Qualifier("deadLetterConsumerFactory")
    private final ConsumerFactory<String, DeadLetter<?>> deadLetterConsumerFactory;
    private final KafkaTopicProperties kafkaTopicProperties;

    private static final String DEAD_LETTER_GROUP_ID = "group-order-dead-letter";
    private static final String CLIENT_SUFFIX = "dlt-client";
    private static final String RETRY_COUNT_HEADER = "x-retry-count";

    @Override
    public void retry() {
        String topic = kafkaTopicProperties.getName(MessageOrderType.ORDER_DLQ);
        try (Consumer<String, DeadLetter<?>> c =
                     deadLetterConsumerFactory.createConsumer(DEAD_LETTER_GROUP_ID, CLIENT_SUFFIX)) {

            List<PartitionInfo> infos = c.partitionsFor(topic);
            if (infos == null || infos.isEmpty()) {
                log.info("DLQ topic has no partitions: {}", topic);
                return;
            }

            List<TopicPartition> tps = infos.stream()
                    .map(pi -> new TopicPartition(topic, pi.partition()))
                    .toList();

            c.assign(tps);

            Map<TopicPartition, OffsetAndMetadata> committed = c.committed(new HashSet<>(tps));
            for (TopicPartition tp : tps) {
                OffsetAndMetadata m = committed != null ? committed.get(tp) : null;
                if (m == null) c.seekToBeginning(Collections.singleton(tp));
                else c.seek(tp, m.offset());
            }

            ConsumerRecords<String, DeadLetter<?>> recs = c.poll(Duration.ofSeconds(2));
            if (recs == null || recs.isEmpty()) {
                log.info("DLQ empty (no records polled)");
                return;
            }

            int processed = 0;
            for (TopicPartition tp : recs.partitions()) {
                List<ConsumerRecord<String, DeadLetter<?>>> list = recs.records(tp);
                long last = -1L;
                for (var r : list) {
                    processOne(c, r);
                    processed++;
                    last = r.offset();
                }
                if (last >= 0) {
                    c.commitSync(Collections.singletonMap(tp, new OffsetAndMetadata(last + 1)));
                    log.info("DLQ commit tp={}, lastOffsetCommitted={}", tp, last + 1);
                }
            }

            log.info("DLQ processed count={}", processed);

        } catch (Exception e) {
            log.error("dead-letter facade error", e);
            throw new CommonException(BatchExceptionCode.POLLING_FAILED);
        }
    }

    protected void processOne(Consumer<String, DeadLetter<?>> c,
                              ConsumerRecord<String, DeadLetter<?>> r) {
        Map<String, String> headers = extractHeaders(r.headers());
        normalizeRetryCount(headers);

        DeadLetter<?> dlq = r.value();
        MessageOrderType t = resolveTypeSafely(dlq.type());
        String orderId = resolveOrderId(headers);

        log.info("DLQ record tp={}-{}, offset={}, key={}, type={}, orderId={}, headers={}",
                r.topic(), r.partition(), r.offset(), r.key(), t, orderId, headers);

        switch (t) {
            case ORDER_LOCAL -> orderDeadLetterService.retryLocal(dlq, headers);
            case ORDER_API -> orderDeadLetterService.retryApi(dlq, headers);
            case ORDER_CRUD -> orderDeadLetterService.retryCrud(dlq, headers);
            default -> throw new CommonException(BatchExceptionCode.UNSUPPORTED_DLQ_TYPE);
        }
    }

    // extractHeaders / normalizeRetryCount / resolveOrderId / resolveTypeSafely : í˜„ì¬ ì½”ë“œ ë™ì¼
}
```

### 3.5 í”„ë¡œë“€ì„œ ì„œë¹„ìŠ¤

- `service.common.impl.KafkaProducerServiceImpl`
    - `KafkaProducerCluster` ì´ìš©
    - í† í”½ëª…: `KafkaTopicProperties.getName(MessageOrderType.*.name())`
    - `sendToLocal/Api/Crud(+headers)`, `sendToDlq(í—¤ë” í¬í•¨ ì˜¤ë²„ë¡œë“œ)`, `sendToDiscard`(ALARM í† í”½)
    - `ErrorDetail` ìƒì„± ì‹œ ìŠ¤íƒ ì œí•œ/NULL ì„¸ì´í”„ ì²˜ë¦¬

```java

@Slf4j
@Component
@RequiredArgsConstructor
@EnableConfigurationProperties({KafkaTopicProperties.class})
public class KafkaProducerServiceImpl implements KafkaProducerService {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)
}
```

---

## 4) DLQ ì¬ì²˜ë¦¬ ì„œë¹„ìŠ¤ ë¡œì§

- `service.retry.impl.OrderDeadLetterServiceImpl`
    - ì…ë ¥: `DeadLetter<?>` (JsonDeserializer ê²½ìœ )
    - payloadë¥¼ ì•ˆì „ ë³€í™˜(Map/JsonNode â†’ DTO)
    - í˜„ì¬ ì¬ì‹œë„ ì¹´ìš´íŠ¸ `current` ê³„ì‚°(ë©”íƒ€/í—¤ë” í›„ë³´í‚¤ì˜ â€œìœ íš¨ ìˆ«ì ìµœëŒ€ê°’â€)
        - ë©”íƒ€ ìš°ì„  í‚¤: `retryCount`(`PRIMARY_RETRY_KEY`)
        - í—¤ë” í›„ë³´ í‚¤: `x-retry-count`, `retry-count`, `x_delivery_attempts`, `deliveryAttempts` ë“±
    - ì„ê³„ì¹˜ ë¹„êµëŠ” **ì¦ê°€ ì „(`current`)** ìœ¼ë¡œ ìˆ˜í–‰
        - `current >= MAX` â†’ ALARM í† í”½ìœ¼ë¡œ íê¸°(`sendToDiscard`)
        - `current <  MAX` â†’ ì¬ì „ì†¡, ì´ë•Œë§Œ `next=current+1` ë¡œ ë©”íƒ€/í—¤ë” **ë™ì‹œ ë°˜ì˜**
    - íƒ€ì…ë³„ ì„ê³„ì¹˜: `LOCAL=5`, `API=3`, `CRUD=5`
    - ê³µí†µ ë³´ì¡°ê¸°: `Bumped<T>`(ì¦ê°€ëœ DeadLetter + í—¤ë” ë§µ)

```java

@Service
@RequiredArgsConstructor
@Slf4j
public class OrderDeadLetterServiceImpl implements OrderDeadLetterService {
    // retryLocal / retryApi / retryCrud â€” í˜„ì¬ ì½”ë“œì™€ ë™ì¼í•œ ì •ì±… êµ¬í˜„
}
```

---

## 5) Secrets/Crypto í‚¤ ì‹œë”©

### 5.1 ì•± í”„ë¡œí¼í‹° ë°”ì¸ë”©

- `config.properties.AppCryptoKeyProperties`
    - `prefix=app.crypto`, `keys[logical-name].{alias, encryptor, kid|version}`
    - encryptor ë¬¸ìì—´ì€ ì‚¬ëŒ ì¹œí™”ì (`AES-GCM`, `aes_256` ë“±)ë„ í—ˆìš©

```java

@Getter
@Setter
@ConfigurationProperties(prefix = "app.crypto")
public class AppCryptoKeyProperties {
    private Map<String, Alias> keys = new LinkedHashMap<>();

    @Getter
    @Setter
    public static class Alias {
        private String alias;
        private String encryptor;  // "AES128" | "AES256" | "AESGCM"
        private String kid;
        private Integer version;
    }
}
```

### 5.2 í‚¤ ì„ íƒ/ì‹œë”© ì ìš©ê¸°

- `crypto.selection.CryptoKeySelectionApplier`
    - `normalizeAlgorithm()`: í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´/ê³µë°±/ìŠ¬ë˜ì‹œ/ì  ì œê±° í›„ ëŒ€ë¬¸ì â†’ ë‚´ë¶€ enum(`CryptoAlgorithmType`)ë¡œ ë§¤í•‘  
      (`AESGCM`/`AES256`/`AES128`/`SHA256`/`SHA512`/`HMAC_SHA256` ë“±)
    - `secrets.applySelection(alias, version, kid, allowLatest)`
    - `secrets.getKey(alias)` ê°€ì ¸ì™€ **Base64 ì¸ì½”ë”© ë¬¸ìì—´**ë¡œ Encryptor/Signerì— ì‹œë”©
    - ê¸°ë³¸ ì •ì±…: **ìë™ ìµœì‹  ê¸ˆì§€(allowLatest=false)**, ìš´ì˜ ìŠ¹ì¸ ì‹œ ìˆ˜ë™ ìŠ¹ê²©

```java

@Slf4j
@Component
@RequiredArgsConstructor
public class CryptoKeySelectionApplier {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ; normalizeAlgorithm / applyAll(false) ë“±)
}
```

### 5.3 Secrets ë¡œë“œ ë¦¬ìŠ¤ë„ˆ

- `lifecycle.crypto.listener.CryptoKeyRefreshListener`
    - `@ConditionalOnBean(SecretsLoader, CryptoKeySelectionApplier)`
    - `onSecretKeyRefreshed` â†’ `applier.applyAll(false)` (ìë™ ë°˜ì˜ ê¸ˆì§€)

```java

@Slf4j
@Component
@RequiredArgsConstructor
@ConditionalOnBean({SecretsLoader.class, CryptoKeySelectionApplier.class})
public class CryptoKeyRefreshListener implements SecretKeyRefreshListener {
    private final CryptoKeySelectionApplier applier;

    @Override
    public void onSecretKeyRefreshed() {
        applier.applyAll(false);
        log.info("[Secrets] í‚¤ ë¦¬í”„ë ˆì‹œ ì´ë²¤íŠ¸ ìˆ˜ì‹ (ìë™ ì ìš© ê¸ˆì§€). ìš´ì˜ ìŠ¹ì¸ ì‹œ ë³„ë„ ê²½ë¡œì—ì„œ applyAll(true) í˜¸ì¶œ ê¶Œì¥.");
    }
}
```

---

## 6) S3 ë¡œê·¸ ë™ê¸°í™”(ì‹œì‘/ì¢…ë£Œ í›…)

### 6.1 ì‹œì‘ í›…

- `lifecycle.handler.ApplicationStartupHandlerImpl`
    - í”„ë¡œí•„: `local/dev/beta/prod`, ì¡°ê±´: `aws.s3.enabled=true`, `@ConditionalOnBean(S3LogSyncService)`
    - ë¡œê·¸ ë””ë ‰í„°ë¦¬ ì¤€ë¹„(ì—†ìœ¼ë©´ ìƒì„±, ë””ë ‰í„°ë¦¬ ì•„ë‹˜ì´ë©´ ìŠ¤í‚µ)
    - ê¸°ì¡´ íŒŒì¼ 1íšŒ ì—…ë¡œë“œ(`S3LogSyncService.syncFileToS3`)
    - `CryptoKeySelectionApplier` ì¡´ì¬ ì‹œ â€œì´ˆê¸° ë¡œë“œ ì´ë²¤íŠ¸ë¡œ ì‹œë”©ë¨â€ ì•ˆë‚´
    - `SecretsLoader.schedule` ì·¨ì†Œ(ì‹œì‘ í›„ ì£¼ê¸° ë¡œë“œ ì°¨ë‹¨)

```java

@Slf4j
@Component
@RequiredArgsConstructor
@EnableConfigurationProperties(S3Properties.class)
@Profile({"local", "dev", "beta", "prod"})
@ConditionalOnProperty(prefix = "aws.s3", name = "enabled", havingValue = "true")
@ConditionalOnBean(S3LogSyncService.class)
public class ApplicationStartupHandlerImpl implements ApplicationStartupHandler, SmartLifecycle {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)
}
```

### 6.2 ì¢…ë£Œ í›…

- `lifecycle.handler.ApplicationShutdownHandlerImpl`
    - í”„ë¡œí•„/ì¡°ê±´ ë™ì¼
    - ì¢…ë£Œ ì‹œì ì— ë¡œê·¸ ë””ë ‰í„°ë¦¬ íŒŒì¼ë“¤ **ìŠ¤ëƒ…ìƒ· ì—…ë¡œë“œ**(ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸)
    - ì´í›„ `SecretsLoader.cancelSchedule()`, `SecretsManagerClient.close()`, `SecretsKeyResolver.wipeAll()` ìˆœì„œë¡œ ì •ë¦¬

```java

@Slf4j
@Component
@RequiredArgsConstructor
@EnableConfigurationProperties(S3Properties.class)
@Profile({"local", "dev", "beta", "prod"})
@ConditionalOnProperty(prefix = "aws.s3", name = "enabled", havingValue = "true")
public class ApplicationShutdownHandlerImpl implements ApplicationShutdownHandler, SmartLifecycle {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)
}
```

### 6.3 S3 ë™ê¸°í™” ì„œë¹„ìŠ¤

- `service.synchronize.impl.S3LogSyncServiceImpl` (`@ConditionalOnProperty aws.s3.enabled=true`)
    - `@PostConstruct`: ë²„í‚· ì¡´ì¬/ìƒì„±, prefix placeholder(`.keep`) ìƒì„±(ì˜µì…˜)
    - `syncFileToS3`: íŒŒì¼ì„ `.upload/*.snapshot`ìœ¼ë¡œ ë³µì œ í›„ **MD5 â†’ ETag ë¹„êµ**, ê°™ìœ¼ë©´ ì—…ë¡œë“œ ìŠ¤í‚µ
    - `HOSTNAME` í¬í•¨ íŒŒì¼ë§Œ ì—…ë¡œë“œ(ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤ êµ¬ë¶„)

```java

@Slf4j
@Service
@RequiredArgsConstructor
@ConditionalOnProperty(prefix = "aws.s3", name = "enabled", havingValue = "true")
public class S3LogSyncServiceImpl implements S3LogSyncService {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)
}
```

### 6.4 ë¹„ë¡œì»¬ í™˜ê²½ ìˆ˜ë™ ì‹¤í–‰ íŒŒì‚¬ë“œ

- `facade.synchronize.impl.S3LogSyncFacadeImpl` (`@Profile !local`)
    - ì§€ì • ë¡œê·¸ ë””ë ‰í„°ë¦¬ ì „ì²´ë¥¼ ìˆœíšŒí•˜ì—¬ `syncFileToS3` ìœ„ì„

```java

@Slf4j
@Component
@RequiredArgsConstructor
@EnableConfigurationProperties(S3Properties.class)
@Profile({"!local"})
public class S3LogSyncFacadeImpl implements S3LogSyncFacade {
    // ... (í˜„ì¬ ì½”ë“œ ê·¸ëŒ€ë¡œ)
}
```

---

## 7) ë¹„ë™ê¸° MDC ì „íŒŒ / ë°°ì¹˜ ì¢…ë£Œì½”ë“œ

- **AsyncConfig** (`@EnableAsync`)
    - `ThreadPoolTaskExecutor(8/32/1000)` + `TaskDecorator`ë¡œ MDC ì»¨í…ìŠ¤íŠ¸ ë³µì œ/ë³µì›

```java

@Configuration
@EnableAsync
public class AsyncConfig {
    @Bean(name = "asyncExecutor")
    public Executor asyncExecutor() {
        ThreadPoolTaskExecutor ex = new ThreadPoolTaskExecutor();
        ex.setCorePoolSize(8);
        ex.setMaxPoolSize(32);
        ex.setQueueCapacity(1000);
        ex.setThreadNamePrefix("async-");
        ex.setTaskDecorator(mdcTaskDecorator());
        ex.initialize();
        return ex;
    }

    @Bean
    public TaskDecorator mdcTaskDecorator() { /* í˜„ì¬ ì½”ë“œ ë™ì¼ */ }
}
```

- **BatchExitCodeConfig**
    - `JobExecutionListenerSupport.afterJob` â†’ `COMPLETED=0`, ê·¸ ì™¸ `=1`ì„ `AtomicInteger`ì— ê¸°ë¡
    - `ExitCodeGenerator` â†’ `SpringApplication.exit(ctx)` ì‹œ ì½í˜€ì„œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œì½”ë“œ ê²°ì •

```java

@Configuration
public class BatchExitCodeConfig {
    @Bean
    public AtomicInteger batchExitCodeHolder() {
        return new AtomicInteger(0);
    }

    @Bean
    public JobExecutionListenerSupport jobExitCodeListener(AtomicInteger holder) {
        return new JobExecutionListenerSupport() {
            @Override
            public void afterJob(JobExecution jobExecution) {
                holder.set(jobExecution.getStatus() == BatchStatus.COMPLETED ? 0 : 1);
            }
        };
    }

    @Bean
    public ExitCodeGenerator batchExitCodeGenerator(AtomicInteger holder) {
        return holder::get;
    }
}
```

---

## 8) ì˜ˆì™¸ ì½”ë“œ

- **BatchExceptionCode**
    - `EMPTY_MESSAGE(6001)`, `MESSAGE_TRANSMISSION_FAILED(6002)`, `POLLING_FAILED(6003)`,  
      `UNSUPPORTED_EVENT_CATEGORY(6004)`, `UNSUPPORTED_DLQ_TYPE(6005)`

```java

@Getter
public enum BatchExceptionCode implements ExceptionCodeEnum {
    EMPTY_MESSAGE(6001, "Message is empty", HttpStatus.BAD_REQUEST),
    MESSAGE_TRANSMISSION_FAILED(6002, "Message transmission failed", HttpStatus.INTERNAL_SERVER_ERROR),
    POLLING_FAILED(6003, "Message polling failed", HttpStatus.INTERNAL_SERVER_ERROR),
    UNSUPPORTED_EVENT_CATEGORY(6004, "Unsupported event category", HttpStatus.INTERNAL_SERVER_ERROR),
    UNSUPPORTED_DLQ_TYPE(6005, "Dlq Type is not unregistered", HttpStatus.INTERNAL_SERVER_ERROR);
    // ...
}
```

---

## 9) ì„¤ì •(YAML) ì˜ˆì‹œ (prod)

- S3/Secrets/Kafka ìë™êµ¬ì„±ì— ë§ì¶˜ ìƒ˜í”Œ(í•µì‹¬ë§Œ)

```yaml
spring:
  config:
    activate:
      on-profile: prod
    import:
      - application-core-prod.yml
      - application-kafka-prod.yml
  batch:
    job:
      name: ${JOB_NAME:NONE}     # ì‹¤í–‰í•  ë°°ì¹˜ ì¡ ì´ë¦„ (NONEì´ë©´ ìë™ ì‹¤í–‰ ì•ˆ í•¨)
      enabled: true
    jdbc:
      initialize-schema: always  # ë°°ì¹˜ ë©”íƒ€í…Œì´ë¸” ìë™ ìƒì„±

aws:
  endpoint: ${AWS_ENDPOINT:}        # LocalStack ë“± ì‚¬ìš© ì‹œ ì§€ì •, ì‹¤AWSë©´ ë¹ˆ ê°’
  region: ${AWS_REGION:ap-northeast-2}
  s3:
    enabled: true
    bucket: ${AWS_S3_BUCKET:my-bucket}
    default-folder: ${AWS_S3_DEFAULT_FOLDER:logs}
    auto-create: true
    create-prefix-placeholder: true

app:
  crypto:
    keys:
      orderAesGcm:
        alias: "order.aesgcm"
        encryptor: "AESGCM"
        kid: "key-2025-09-27"
      userPhoneAes256:
        alias: "user.phone.aes256"
        encryptor: "AES256"
        version: 2
```

- ì°¸ê³ 
    - `aws.s3.enabled=true` ì—¬ì•¼ AmazonS3/S3Client ë¹ˆ ìƒì„±
    - endpoint ë¯¸ì§€ì • ì‹œ region í•„ìˆ˜
    - Kafka í† í”½ ì´ë¦„ì€ `KafkaTopicProperties`ì— ìœ„ì„ (MessageOrderType ê¸°ë°˜)

---

## 10) ì‹¤í–‰/ì¢…ë£Œ

- íŠ¹ì • ì¡ë§Œ ì‹¤í–‰(ì˜ˆ: **DLQ ì¬ì²˜ë¦¬**)

```bash
java -DJOB_NAME=ORDER_DEAD_LETTER_JOB -jar order-batch.jar --spring.profiles.active=prod
```

- ì¢…ë£Œì½”ë“œ
    - `COMPLETED` â†’ **0**
    - `FAILED` ë“± â†’ **1**
    - CI/CD/ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ â€œì„±ê³µ/ì‹¤íŒ¨ ë¶„ê¸°â€ì— ë°”ë¡œ í™œìš© ê°€ëŠ¥

---

## 11) í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

- **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**
    - `OrderDeadLetterServiceImpl`: current ê³„ì‚°(ë©”íƒ€/í—¤ë”), ì„ê³„ì¹˜ ë¶„ê¸°, bump ë™ì‘ ê²€ì¦
    - `CryptoKeySelectionApplier`: normalizeAlgorithm ë§¤í•‘, applySelection ì‹¤íŒ¨/ì„±ê³µ ê²½ë¡œ
    - `S3LogSyncServiceImpl`: ETag=MD5 ë™ì¼ ì‹œ ìŠ¤í‚µ, ìŠ¤ëƒ…ìƒ· ì‚­ì œ ë³´ì¥

- **í†µí•© í…ŒìŠ¤íŠ¸**
    - EmbeddedKafka: DLQì— `DeadLetter<?>` ì ì¬ â†’ ì¡ ì‹¤í–‰ â†’ ì¬ë°œí–‰/íê¸° í† í”½ ìˆ˜ì‹  ê²€ì¦
    - ë¡œì»¬ í”„ë¡œí•„ì—ì„œ `KafkaTopicsConfig` `ensure-at-startup=true` ë¡œ í† í”½ ë³´ì¥

---

## 12) í•œ ì¤„ ìš”ì•½

ìš´ì˜ ì¹œí™”ì ì¸ **ë‹¨ë°œì„± ë°°ì¹˜ í”Œë«í¼**:  
DLQ ì¬ì²˜ë¦¬(DeadLetter<?> ì§ì ‘ ì—­ì§ë ¬í™”), S3 ë¡œê·¸ ì—…ë¡œë“œ ë³´ê°•, Secrets/Crypto í‚¤ ì‹œë”©(ìë™ ìµœì‹  ê¸ˆì§€), ì¢…ë£Œì½”ë“œ ë§¤í•‘ê¹Œì§€ **í˜„ì—… ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ** êµ¬ì„±ì„ ì œê³µí•©ë‹ˆë‹¤.
