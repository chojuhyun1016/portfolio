# ğŸ§° order-batch ì„œë¹„ìŠ¤ README (Spring Batch Â· DLQ ì¬ì²˜ë¦¬ Â· S3 ì—…ë¡œë“œ Â· êµ¬ì„±/í™•ì¥/ìš´ì˜ ê°€ì´ë“œ)

Spring Boot ê¸°ë°˜ **ë°°ì¹˜ ëª¨ë“ˆ**ì…ë‹ˆë‹¤.  
Kafka DLQ(Dead Letter Queue) ì¬ì²˜ë¦¬ ì¡ê³¼ S3 ì—…ë¡œë“œ ìœ í‹¸ì„ ì œê³µí•˜ë©°, ì½”ì–´/í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆì€ **ì„¤ì •(@Import)** ìœ¼ë¡œ ì¡°ë¦½í•˜ê³ , ë°°ì¹˜ ëª¨ë“ˆ ë‚´ë¶€ë§Œ **ì»´í¬ë„ŒíŠ¸ ìŠ¤ìº”**í•©ë‹ˆë‹¤.  
ì„¤ì •ì€ **YAML ì¤‘ì‹¬**, í† í”½ëª…ì€ `MessageCategory` â†’ `KafkaTopicProperties` ë¡œ íƒ€ì… ì„¸ì´í”„í•˜ê²Œ ì£¼ì…í•©ë‹ˆë‹¤.

---

## 1) ì „ì²´ êµ¬ì¡°

| ë ˆì´ì–´ | ì£¼ìš” íŒ¨í‚¤ì§€/í´ë˜ìŠ¤ | í•µì‹¬ ì—­í•  |
|---|---|---|
| ì¡°ë¦½/ë¶€íŠ¸ìŠ¤íŠ¸ë© | org.example.order.batch.config.OrderBatchConfig | ì½”ì–´/í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ Import, ë°°ì¹˜ íŒ¨í‚¤ì§€ ìŠ¤ìº”, BatchProperties ë°”ì¸ë”©, ObjectMapper ê¸°ë³¸ ë¹ˆ |
| ì¡/ìŠ¤í…/íƒœìŠ¤í¬ë¦¿ | org.example.order.batch.job.OrderDeadLetterJob | DLQ ì¬ì²˜ë¦¬ Job/Step/Tasklet ì •ì˜ |
| íŒŒì‚¬ë“œ | org.example.order.batch.facade.retry.impl.OrderDeadLetterFacadeImpl | Kafka DLQ íŒŒí‹°ì…˜ ìˆ˜ë™ ì†Œë¹„, ì˜¤í”„ì…‹ ê´€ë¦¬, ì¬ì²˜ë¦¬ ìœ„ì„ |
| ì„œë¹„ìŠ¤(ê³µí†µ) | FileServiceImpl, KafkaProducerServiceImpl, S3ServiceImpl | íŒŒì¼â†’S3 ì—…ë¡œë“œ, ì¹´í”„ì¹´ ë°œí–‰(DLQ/Discard í¬í•¨), S3 ë˜í¼ |
| ì„œë¹„ìŠ¤(DLQ) | OrderDeadLetterServiceImpl | DLQ ë©”ì‹œì§€ íƒ€ì… ë¶„ê¸°(LOCAL/API/CRUD), ì‹¤íŒ¨ íšŸìˆ˜ ê¸°ì¤€ discard íŒë‹¨ |
| ì˜ˆì™¸/ì½”ë“œ | BatchExceptionCode | ë°°ì¹˜ ì „ìš© í‘œì¤€ ì˜¤ë¥˜ ì½”ë“œ |

ë©”ì‹œì§€ ì¹´í…Œê³ ë¦¬(ì¼ë¶€): ORDER_LOCAL, ORDER_API, ORDER_CRUD, ORDER_DLQ, ORDER_ALARM  
DLQ ì¬ì²˜ë¦¬ íƒ€ì…: DlqOrderType.ORDER_LOCAL, ORDER_API, ORDER_CRUD

---

## 2) ë™ì‘ íë¦„(ìš”ì•½)

    OrderDeadLetterJob (Tasklet)
      â†’ OrderDeadLetterFacadeImpl.retry()
         â†’ Kafka Consumer (DLQ í† í”½ íŒŒí‹°ì…˜ 0 ìˆ˜ë™ í• ë‹¹, ì˜¤í”„ì…‹ ì§€ì •)
            â†’ poll â†’ record.value() ì „ë‹¬
               â†’ OrderDeadLetterServiceImpl.retry(...)
                  â†’ DlqOrderType ì— ë”°ë¼ Producerë¡œ ì¬ë°œí–‰(sendToLocal/Api/Crud)
                  â†’ ì‹¤íŒ¨ ëˆ„ì ì´ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ discard í† í”½ìœ¼ë¡œ ì „ì†¡

ì›ì¹™:
- íŒŒì‚¬ë“œ: ì»¨ìŠˆë¨¸ ìƒì„±/ì˜¤í”„ì…‹ ê²°ì •/ë£¨í”„ ì²˜ë¦¬/ì»¤ë°‹ â€” í•µì‹¬ ê²½ë¡œë§Œ ìˆ˜í–‰
- ì„œë¹„ìŠ¤: íƒ€ì… ì•ˆì „ ë³€í™˜(ObjectMapperUtils), ì‹¤íŒ¨ íšŒìˆ˜ ì¦ê°€, Discard ì„ê³„ê°’ ì²´í¬
- í”„ë¡œë“€ì„œ: DLQ/Discard/ì¼ë°˜ í† í”½ ë°œí–‰ ê³µí†µ send(...) ê²½ë¡œ ìœ ì§€

---

## 3) ì¡°ë¦½/êµ¬ì„±

### 3.1 OrderBatchConfig

    @Configuration
    @Import({
            OrderCoreConfig.class,     // ì½”ì–´ ì¸í”„ë¼(ë„ë©”ì¸/JPA/ë½/ë ˆë””ìŠ¤ ë“±)
            KafkaModuleConfig.class,   // Kafka í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ
            S3ModuleConfig.class       // S3 í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ
    })
    @EnableConfigurationProperties(BatchProperties.class)
    @ComponentScan(basePackages = {
            "org.example.order.batch.config",
            "org.example.order.batch.application",
            "org.example.order.batch.facade",
            "org.example.order.batch.job",
            "org.example.order.batch.service"
    })
    public class OrderBatchConfig {

        @Bean
        @ConditionalOnMissingBean(ObjectMapper.class)
        ObjectMapper objectMapper() {
            return ObjectMapperFactory.defaultObjectMapper();
        }
    }

- ì™¸ë¶€ ëª¨ë“ˆì€ @Import ë¡œë§Œ ì¡°ë¦½í•˜ê³ , **ì™¸ë¶€ íŒ¨í‚¤ì§€ëŠ” ìŠ¤ìº”í•˜ì§€ ì•ŠìŒ**
- BatchProperties ë°”ì¸ë”© í™œì„±í™”
- ObjectMapper ëŠ” ì™¸ë¶€ ì œê³µ ì‹œ ì¤‘ë³µ ìƒì„± ë°©ì§€

### 3.2 ë°°ì¹˜ ì¡/ìŠ¤í…/íƒœìŠ¤í¬ë¦¿

    @Configuration
    @RequiredArgsConstructor
    @Slf4j
    public class OrderDeadLetterJob {

        private final OrderDeadLetterFacade facade;
        public static final String JOB_NAME = "ORDER_DEAD_LETTER_JOB";

        // ì¡ ì •ì˜
        @Bean(name = JOB_NAME)
        public Job job(JobRepository jobRepository, Step orderDeadLetterStep) {
            return new JobBuilder(JOB_NAME, jobRepository)
                    .start(orderDeadLetterStep)
                    .preventRestart()
                    .build();
        }

        // ìŠ¤í… ì •ì˜
        @Bean
        @JobScope
        public Step orderDeadLetterStep(JobRepository jobRepository,
                                        Tasklet orderDeadLetterTasklet,
                                        PlatformTransactionManager platformTransactionManager) {
            return new StepBuilder(String.format("%s.%s", JOB_NAME, "retry"), jobRepository)
                    .tasklet(orderDeadLetterTasklet, platformTransactionManager)
                    .build();
        }

        // íƒœìŠ¤í¬ë¦¿: DLQ ì¬ì²˜ë¦¬ ì‹¤í–‰
        @Bean
        @JobScope
        public Tasklet orderDeadLetterTasklet() {
            return (contribution, chunkContext) -> {
                log.info("OrderDeadLetterJob start");
                facade.retry();
                return RepeatStatus.FINISHED;
            };
        }
    }

---

## 4) Kafka DLQ ì¬ì²˜ë¦¬

### 4.1 íŒŒì‚¬ë“œ: OrderDeadLetterFacadeImpl (í•µì‹¬ ë‹¨ê³„)

- DLQ í† í”½ ì¡°íšŒ
- ì»¨ìŠˆë¨¸ ìƒì„± (ê·¸ë£¹/í´ë¼ì´ì–¸íŠ¸ suffix)
- íŒŒí‹°ì…˜ 0 ìˆ˜ë™ í• ë‹¹
- ì‹œì‘ ì˜¤í”„ì…‹ ê²°ì •(ì»¤ë°‹ ì—†ìœ¼ë©´ beginning)
- ì „ì²´ ë©”ì‹œì§€ ìˆ˜ ê³„ì‚°(end-offset - position)
- ë£¨í”„: poll â†’ ì„œë¹„ìŠ¤ì— ìœ„ì„ â†’ commitSync

  @RequiredArgsConstructor
  @Slf4j
  @Component
  public class OrderDeadLetterFacadeImpl implements OrderDeadLetterFacade {

        private final OrderDeadLetterService orderDeadLetterService;
        private final ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory;
        private final KafkaTopicProperties kafkaTopicProperties;

        private static final String DEAD_LETTER_GROUP_ID = "order-order-dead-letter";
        private static final String CLIENT_SUFFIX = "dlt-client";

        @Override
        public void retry() {
            try {
                // DLQ í† í”½
                String topic = kafkaTopicProperties.getName(MessageCategory.ORDER_DLQ);

                // Consumer ìƒì„±
                ConsumerFactory<String, String> factory =
                        (ConsumerFactory<String, String>) kafkaListenerContainerFactory.getConsumerFactory();
                Consumer<String, String> consumer = factory.createConsumer(DEAD_LETTER_GROUP_ID, CLIENT_SUFFIX);

                // íŒŒí‹°ì…˜ í• ë‹¹
                TopicPartition partition = new TopicPartition(topic, 0);
                Set<TopicPartition> partitions = Collections.singleton(partition);
                consumer.assign(partitions);

                // ì‹œì‘ offset ì§€ì •
                Map<TopicPartition, OffsetAndMetadata> committedOffsets = consumer.committed(partitions);
                if (committedOffsets.get(partition) == null) {
                    consumer.seekToBeginning(partitions);
                } else {
                    consumer.seek(partition, committedOffsets.get(partition).offset());
                }

                // ì „ì²´ ë©”ì‹œì§€ ìˆ˜
                long endOffset = consumer.endOffsets(partitions).get(partition);
                long currentOffset = consumer.position(partition);
                long messageCount = endOffset - currentOffset;
                long consumedCount = 0L;

                log.debug("number of messages : {}", messageCount);

                // ë©”ì‹œì§€ ì²˜ë¦¬ ë£¨í”„
                while (consumedCount < messageCount) {
                    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(2000));
                    if (records.count() == 0) {
                        throw new CommonException(BatchExceptionCode.POLLING_FAILED);
                    }

                    for (ConsumerRecord<String, String> record : records.records(topic)) {
                        orderDeadLetterService.retry(record.value());
                    }

                    consumedCount += records.count();
                    consumer.commitSync();
                }

                consumer.close();
            } catch (Exception e) {
                log.error("error : order dead letter retry failed", e);
                throw e;
            }
        }
  }

### 4.2 ì„œë¹„ìŠ¤: OrderDeadLetterServiceImpl

í•µì‹¬ í¬ì¸íŠ¸:
- ì›ë³¸ ë¬¸ìì—´ì—ì„œ DlqOrderType í•„ë“œë§Œ ì¶”ì¶œ â†’ íƒ€ì… ë¶„ê¸°
- ê° íƒ€ì…ì˜ ë©”ì‹œì§€ í´ë˜ìŠ¤ë¡œ ì—­ì§ë ¬í™” â†’ ì‹¤íŒ¨ íšŒìˆ˜ ì¦ê°€
- maxFailCount ì´ˆê³¼ ì‹œ discard, ì•„ë‹ˆë©´ ì¬ë°œí–‰

  @RequiredArgsConstructor
  @Slf4j
  @Service
  @EnableConfigurationProperties({KafkaConsumerProperties.class})
  public class OrderDeadLetterServiceImpl implements OrderDeadLetterService {

        private final KafkaProducerService kafkaProducerService;
        private final KafkaConsumerProperties kafkaConsumerProperties;

        // DLQ ë©”ì‹œì§€ ìœ í˜•ë³„ ì¬ì²˜ë¦¬
        @Override
        public void retry(Object message) {
            DlqOrderType type = ObjectMapperUtils.getFieldValueFromString(message.toString(), "type", DlqOrderType.class);
            log.info("DLQ ì²˜ë¦¬ ì‹œì‘ - Type: {}", type);

            switch (type) {
                case ORDER_LOCAL -> retryMessage(message, OrderLocalMessage.class, kafkaProducerService::sendToLocal);
                case ORDER_API   -> retryMessage(message, OrderApiMessage.class, kafkaProducerService::sendToOrderApi);
                case ORDER_CRUD  -> retryMessage(message, OrderCrudMessage.class, kafkaProducerService::sendToOrderCrud);
                default -> throw new CommonException(BatchExceptionCode.UNSUPPORTED_DLQ_TYPE);
            }
        }

        // ê°œë³„ ë©”ì‹œì§€ ì¬ì²˜ë¦¬ ë¡œì§
        private <T extends DlqMessage> void retryMessage(Object rawMessage, Class<T> clazz, java.util.function.Consumer<T> retrySender) {
            T dlqMessage = ObjectMapperUtils.valueToObject(rawMessage, clazz);
            dlqMessage.increaseFailedCount();

            if (shouldDiscard(dlqMessage)) {
                kafkaProducerService.sendToDiscard(dlqMessage);
            } else {
                retrySender.accept(dlqMessage);
            }
        }

        // ìµœëŒ€ ì‹¤íŒ¨ íšŸìˆ˜ ì´ˆê³¼ ì‹œ discard
        private <T extends DlqMessage> boolean shouldDiscard(T message) {
            return message.discard(kafkaConsumerProperties.getOption().getMaxFailCount());
        }
  }

---

## 5) ê³µí†µ ì„œë¹„ìŠ¤

### 5.1 KafkaProducerServiceImpl (ìš”ì•½)

- ì¹´í…Œê³ ë¦¬ë³„ ì¼ë°˜ ë°œí–‰: sendToLocal, sendToOrderApi, sendToOrderCrud
- DLQ ì¼ê´„/ë‹¨ê±´ ë°œí–‰: sendToDlq(List<T>, e), sendToDlq(T, e) â€” ì˜ˆì™¸ë¥¼ ë©”ì‹œì§€ì— ì£¼ì… í›„ ë°œí–‰
- Discard ë°œí–‰: sendToDiscard(T) â€” ëª¨ë‹ˆí„°ë§ ë©”ì‹œì§€ë¡œ ALARM í† í”½ ì „ì†¡
- í† í”½ëª…ì€ KafkaTopicProperties.getName(MessageCategory) ë¡œ ì•ˆì „ ì£¼ì…, ê³µí†µ send(Object, topic) ê²½ë¡œ ì‚¬ìš©

  @Slf4j
  @Component
  @RequiredArgsConstructor
  @EnableConfigurationProperties({KafkaTopicProperties.class})
  public class KafkaProducerServiceImpl implements KafkaProducerService {

        private final KafkaProducerCluster cluster;
        private final KafkaTopicProperties kafkaTopicProperties;

        // ë¡œì»¬ ë©”ì‹œì§€ ì „ì†¡
        @Override
        public void sendToLocal(OrderLocalMessage message) {
            send(message, kafkaTopicProperties.getName(MessageCategory.ORDER_LOCAL));
        }

        // API ë©”ì‹œì§€ ì „ì†¡
        @Override
        public void sendToOrderApi(OrderApiMessage message) {
            send(message, kafkaTopicProperties.getName(MessageCategory.ORDER_API));
        }

        // CRUD ë©”ì‹œì§€ ì „ì†¡
        @Override
        public void sendToOrderCrud(OrderCrudMessage message) {
            send(message, kafkaTopicProperties.getName(MessageCategory.ORDER_CRUD));
        }

        // DLQ ë©”ì‹œì§€ ì¼ê´„ ì „ì†¡
        @Override
        public <T extends DlqMessage> void sendToDlq(List<T> messages, Exception currentException) {
            if (ObjectUtils.isEmpty(messages)) {
                return;
            }
            for (T message : messages) {
                sendToDlq(message, currentException);
            }
        }

        // íê¸°(discard) í† í”½ìœ¼ë¡œ ì „ì†¡
        @Override
        public <T extends DlqMessage> void sendToDiscard(T message) {
            log.info("Sending message to discard topic");
            send(MonitoringMessage.toMessage(
                            MonitoringType.ERROR,
                            MonitoringLevelCode.LEVEL_3,
                            message),
                    kafkaTopicProperties.getName(MessageCategory.ORDER_ALARM));
        }

        // DLQ í† í”½ìœ¼ë¡œ ì „ì†¡
        @Override
        public <T extends DlqMessage> void sendToDlq(T message, Exception currentException) {
            if (ObjectUtils.isEmpty(message)) {
                return;
            }
            try {
                if (currentException instanceof CommonException commonException) {
                    message.fail(CustomErrorMessage.toMessage(commonException.getCode(), commonException));
                } else {
                    message.fail(CustomErrorMessage.toMessage(currentException));
                }
                log.info("Sending message to dead letter topic");
                send(message, kafkaTopicProperties.getName(MessageCategory.ORDER_DLQ));
            } catch (Exception e) {
                log.error("error : send message to order-dead-letter failed : {}", message);
                log.error(e.getMessage(), e);
            }
        }

        // ë©”ì‹œì§€ ì „ì†¡ ê³µí†µ ì²˜ë¦¬
        private void send(Object message, String topic) {
            cluster.sendMessage(message, topic);
        }
  }

### 5.2 FileServiceImpl / S3ServiceImpl (ìš”ì•½)

    @Slf4j
    @Service
    @RequiredArgsConstructor
    public class FileServiceImpl implements FileService {

        private final S3Service s3Service;

        // ê°ì²´ë¥¼ íŒŒì¼ë¡œ ë³€í™˜ í›„ S3 ì—…ë¡œë“œ
        @Override
        public void upload(String fileName, String suffix, Object object) {
            try {
                File file = convert(suffix, object);
                s3Service.upload(fileName, file);
            } catch (Exception e) {
                log.error(e.getMessage(), e);
            }
        }

        // ê°ì²´ â†’ JSON ì§ë ¬í™” â†’ ì„ì‹œ íŒŒì¼ ë³€í™˜
        private File convert(String suffix, Object object) throws IOException {
            File tempFile = File.createTempFile("tmp", suffix);
            try (FileOutputStream fos = new FileOutputStream(tempFile)) {
                ObjectMapperUtils.writeValue(fos, object);
            }
            return tempFile;
        }
    }

    @Slf4j
    @Service
    @RequiredArgsConstructor
    @EnableConfigurationProperties(S3Properties.class)
    public class S3ServiceImpl implements S3Service {

        private final S3Client s3Client;
        private final S3Properties s3Properties;

        // íŒŒì¼ ì—…ë¡œë“œ
        @Override
        public void upload(String fileName, File file) {
            try {
                s3Client.putObject(
                        s3Properties.getS3().getBucket(),
                        String.format("%s/%s", s3Properties.getS3().getDefaultFolder(), fileName),
                        file
                );
            } catch (Exception e) {
                log.error("error : fail to upload file", e);
                log.error(e.getMessage(), e);
                throw new CommonException(CommonExceptionCode.UPLOAD_FILE_TO_S3_ERROR);
            }
        }

        // íŒŒì¼ ì½ê¸°
        @Override
        public S3Object read(String key) {
            return s3Client.getObject(s3Properties.getS3().getBucket(), key);
        }
    }

---

## 6) ì„¤ì •(YAML) â€” prod í”„ë¡œí•„

í˜„ì¬ ì½”ë“œ(S3Properties/S3ClientConfig/OrderBatchConfig)ì— ì •í™•íˆ ë§ì¶˜ ìƒ˜í”Œ:

    spring:
      config:
        activate:
          on-profile: prod
        import:
          - application-core-prod.yml
          - application-kafka-prod.yml

      batch:
        job:
          name: ${JOB_NAME:NONE}          # ì‹¤í–‰í•  ë°°ì¹˜ ì¡ ì´ë¦„ (ê¸°ë³¸ NONE â†’ ìë™ ì‹¤í–‰ ì•ˆ í•¨)
          enabled: true                   # ì• í”Œë¦¬ì¼€ì´ì…˜ ê¸°ë™ ì‹œ Job ì‹¤í–‰ ì—¬ë¶€
        jdbc:
          initialize-schema: always       # ë°°ì¹˜ ë©”íƒ€í…Œì´ë¸” ìë™ ìƒì„± (RDS ì´ˆê¸°ê°€ë™/ë¡œì»¬ í¬í•¨)

    aws:
      endpoint: ${AWS_ENDPOINT:}          # LocalStack ë“± í”„ë¡ì‹œ ì‚¬ìš© ì‹œ ì§€ì •, ì‹¤AWSë©´ ë¹ˆ ê°’
      region: ${AWS_REGION:ap-northeast-2}

      credential:
        enabled: false                    # true â†’ access/secret ì‚¬ìš©, false â†’ ê¸°ë³¸ ìê²©ì¦ëª… ì²´ì¸(IAM Role ë“±)
        accessKey: ${AWS_ACCESS_KEY:}
        secretKey: ${AWS_SECRET_KEY:}

      s3:
        enabled: true
        bucket: ${AWS_S3_BUCKET:my-bucket}
        default-folder: ${AWS_S3_DEFAULT_FOLDER:tmp}

ì£¼ì˜:
- aws.s3.enabled=true ì—¬ì•¼ AmazonS3/S3Client ë¹ˆ ìƒì„±(@ConditionalOnProperty)
- endpoint ë¯¸ì§€ì • ì‹œ region í•„ìˆ˜
- credential.enabled=true ì‹œ accessKey/secretKey í•„ìˆ˜

---

## 7) ë¹Œë“œ/ëŸ°íƒ€ì„

### 7.1 ë¹Œë“œ(ë²„ì „ ì¹´íƒˆë¡œê·¸ ì¼ì›í™”)
- ëª¨ë“  ì˜ì¡´ì„±ì€ gradle/libs.versions.toml ì˜ alias(libs.*) ë¡œ ê´€ë¦¬
- ë£¨íŠ¸ build.gradle ì˜ í†µí•© í…ŒìŠ¤íŠ¸ ì†ŒìŠ¤ì…‹/íƒœìŠ¤í¬ ê·œì•½ì„ ê·¸ëŒ€ë¡œ ìƒì†
- order-batch ëª¨ë“ˆì€ ë¼ì´ë¸ŒëŸ¬ë¦¬/ë°°ì¹˜ êµ¬ì„± ìœ ì§€(ë¶€íŠ¸ í”ŒëŸ¬ê·¸ì¸ì€ ë£¨íŠ¸ì—ì„œ í†µí•© ê´€ë¦¬)

### 7.2 ì‹¤í–‰
- ê¸°ë³¸ì ìœ¼ë¡œ Jobì€ ê¸°ë™ ì‹œ ìë™ ì‹¤í–‰(enabled: true)
- ì–´ë–¤ Jobì„ ì‹¤í–‰í• ì§€ JOB_NAME ë¡œ ì§€ì •
- ì˜ˆ) DLQ ì¬ì²˜ë¦¬ ì¡ë§Œ ì‹¤í–‰

  java -DJOB_NAME=ORDER_DEAD_LETTER_JOB -jar order-batch.jar --spring.profiles.active=prod

- ìŠ¤í‚¤ë§ˆ ìë™ ì´ˆê¸°í™” ë¹„í™œì„±í™”: spring.batch.jdbc.initialize-schema=never

---

## 8) í™•ì¥ ê°€ì´ë“œ

### 8.1 ìƒˆë¡œìš´ DLQ íƒ€ì… ì¶”ê°€
1) DlqOrderType ì— í•­ëª© ì¶”ê°€ (ì˜ˆ: ORDER_REMOTE)
2) í•´ë‹¹ íƒ€ì…ì˜ ë©”ì‹œì§€ í´ë˜ìŠ¤ ì •ì˜(ì˜ˆ: OrderRemoteMessage)
3) OrderDeadLetterServiceImpl.retry ì˜ switch ì— ë¶„ê¸° ì¶”ê°€
4) KafkaProducerService ì— ëŒ€ì‘ ì „ì†¡ ë©”ì„œë“œ/í† í”½ ë§¤í•‘ ì¶”ê°€

### 8.2 ë©€í‹° íŒŒí‹°ì…˜/ë©€í‹° í† í”½ ì¬ì²˜ë¦¬
- OrderDeadLetterFacadeImpl ì—ì„œ TopicPartition ëª©ë¡ ì£¼ì…/ì¡°íšŒ â†’ ìˆœíšŒ ë˜ëŠ” ë³‘ë ¬í™”
- ì»¤ë°‹/ì—ëŸ¬ ì²˜ë¦¬ ì •ì±…ì„ íŒŒí‹°ì…˜ ë‹¨ìœ„ë¡œ ê²©ë¦¬

### 8.3 ë°°ì¹˜ ì¡ ì¶”ê°€
- Job/Step/Tasklet í´ë˜ìŠ¤ë¥¼ job íŒ¨í‚¤ì§€ì— ì¶”ê°€
- @Bean(name = "JOB_NAME") ë¡œ Job ë“±ë¡, JOB_NAME ìœ¼ë¡œ ì‹¤í–‰ ì œì–´
- ê³µí†µ íŒŒì‚¬ë“œ/ì„œë¹„ìŠ¤/í”„ë¡œë“€ì„œ ì¬ì‚¬ìš©

### 8.4 S3 ìœ í‹¸ í™•ì¥
- ë©±ë“± í‚¤(ë‚ ì§œ/í˜¸ìŠ¤íŠ¸/íŒŒì¼ëª…) í‘œì¤€í™”
- ì²´í¬ì„¬ ë¹„êµ í›„ ì—…ë¡œë“œ ìŠ¤í‚µ
- ì‹¤íŒ¨ ì¬ì‹œë„/ë°±ì˜¤í”„/ì„œí‚·ë¸Œë ˆì´ì»¤ ì ìš©

---

## 9) í…ŒìŠ¤íŠ¸ ì „ëµ

### 9.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- OrderDeadLetterServiceImpl ì˜ íƒ€ì… ë¶„ê¸°/Discard ì¡°ê±´ ê²€ì¦
- KafkaProducerServiceImpl ì˜ DLQ/Discard ì „ì†¡ ê²½ë¡œ ê²€ì¦(Mockito)

### 9.2 í†µí•© í…ŒìŠ¤íŠ¸(ì„ í˜¸)
- EmbeddedKafka ë¡œ DLQ í† í”½ì— í˜ì´ë¡œë“œ ì ì¬ â†’ ì¡ ì‹¤í–‰ â†’ ì¬ë°œí–‰ í† í”½ ìˆ˜ì‹  ê²€ì¦
- ë°°ì¹˜ ë©”íƒ€í…Œì´ë¸” ì´ˆê¸°í™”ê°€ í•„ìš”í•œ ê²½ìš° í…ŒìŠ¤íŠ¸ í”„ë¡œí•„ì—ì„œ initialize-schema=always

ìœ ì˜:
- í†µí•© í…ŒìŠ¤íŠ¸ì—ì„œ ì™¸ë¶€ ëª¨ë“ˆ ìŠ¤ìº”ì„ í¬ê²Œ ì—´ë©´ ì™¸ë¶€ ë¹ˆ ì˜ì¡´ë„ê°€ ì»¤ì ¸ NoSuchBeanDefinitionException ì´ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë‹ˆ, **í…ŒìŠ¤íŠ¸ ì „ìš© ë¶€íŠ¸ êµ¬ì„±**ìœ¼ë¡œ í•„ìš”í•œ ì„¤ì •/ë¹ˆë§Œ ë¡œë”©í•˜ì„¸ìš”.

---

## 10) ì˜ˆì™¸ ì½”ë“œ

- BatchExceptionCode
  - EMPTY_MESSAGE(6001), MESSAGE_TRANSMISSION_FAILED(6002), POLLING_FAILED(6003), UNSUPPORTED_EVENT_CATEGORY(6004), UNSUPPORTED_DLQ_TYPE(6005)
- ì˜ë¯¸
  - POLLING_FAILED: ì»¨ìŠˆë¨¸ poll ê²°ê³¼ 0ê±´ ì§€ì† ë“± ë¹„ì •ìƒ ìƒíƒœ
  - UNSUPPORTED_DLQ_TYPE: ìƒˆë¡œìš´ íƒ€ì… ë¯¸ë“±ë¡ ì‹œ ëª…í™•í•œ ì‹¤íŒ¨

---

## 11) í•œ ì¤„ ìš”ì•½

**ë‹¨ìˆœí•˜ê³  ì•ˆì „í•œ DLQ ì¬ì²˜ë¦¬ ë°°ì¹˜**ì…ë‹ˆë‹¤.  
ì„¤ì •(@Import)ìœ¼ë¡œ ëª¨ë“ˆì„ ì¡°ë¦½í•˜ê³ , ë°°ì¹˜ ë‚´ë¶€ë§Œ ìŠ¤ìº”í•˜ì—¬ ì¶©ëŒì„ ì¤„ì˜€ìœ¼ë©°, S3/ì¹´í”„ì¹´ ìœ í‹¸ì„ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤ë¡œ ë¶„ë¦¬í–ˆìŠµë‹ˆë‹¤. ì¡/ìŠ¤í…/íƒœìŠ¤í¬ë¦¿ì€ ìµœì†Œë‹¨ìœ„ë¡œ ë‚˜ëˆ  í™•ì¥ì´ ì‰½ìŠµë‹ˆë‹¤.
